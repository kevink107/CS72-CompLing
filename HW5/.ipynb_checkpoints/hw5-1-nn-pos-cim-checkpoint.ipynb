{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfXr-CmLZWTa"
      },
      "source": [
        "# Examples for Homework 5.1: Neural Network for Cook Islands Māori Parts of Speech\n",
        "Dartmouth College, LING48, Spring 2023<br>\n",
        "Rolando Coto-Solano (Rolando.A.Coto.Solano@dartmouth.edu)\n",
        "\n",
        "Code modified from:\n",
        "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
        "\n",
        "You need to perform three tasks:\n",
        "\n",
        "(a) Run the program three times and record the training and test accuracy for each of the three runs. What is the average training accuracy? What is the average accuracy for the test set? How are the F1-scores behaving? (You can see more information how the predictions are working by looking at the predictions for the first fifteen items).\n",
        "\n",
        "(b)\tChange the program so that the hidden layers have 48 and 24 neurons, and the output has 3 neurons. Run the modified program three times. What is the average training/test accuracy? How are the F1-scores behaving? (You can see more information how the predictions are working by looking at the predictions for the first ten items).\n",
        "\n",
        "(c)\tUse the same settings as you did in step ‘B’ above and make one more change: Change the program so that it runs for 200 epochs. Run this three times. What is the average training and test accuracy? How are the F1-scores behaving? (You can see more information how the predictions are working by looking at the predictions for the first ten items).\n",
        "\n",
        "Write all of these answers in a PDF/Word/LibreOffice file. Include screeshots of your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3S3JYLuJNee"
      },
      "source": [
        "# load packages (neural network is in sklearn)\n",
        "from numpy import loadtxt\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import layers\n",
        "import gdown\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W48eUFYkLk9M"
      },
      "source": [
        "I recommend that you comment out to cell below and then go to<br>\n",
        "\"Runtime\" > \"Run all\". This will automatically run everything,<br>\n",
        "so you can just record the relevant data and run again and again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x1_Z5D0JiNP"
      },
      "source": [
        "# Load file and split into training data (nX) and\n",
        "# the labels we are trying to predict (ny)\n",
        "\n",
        "cimData = pd.read_csv(\"cim-3pos.csv\")\n",
        "dataset = cimData\n",
        "nX = cimData.drop('tokenPOS', axis=1)\n",
        "ny = cimData['tokenPOS']\n",
        "\n",
        "numberValidPOS = 3  # noun, verb, preposition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpL1ZGCYJo_-"
      },
      "source": [
        "# Encode the words into numbers and then split\n",
        "# the randomly data into training and test sets.\n",
        "\n",
        "encoderX = preprocessing.OneHotEncoder(sparse=True)\n",
        "X = encoderX.fit_transform(nX)\n",
        "encoderY = preprocessing.LabelEncoder()\n",
        "y = encoderY.fit_transform(ny)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10)\n",
        "\n",
        "inputDims = 1497 # the total of features in the OneHotEncoded X vector (total number of unique words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9gAOKT5Mlj2"
      },
      "source": [
        "# Here, you can study what the dataset looks like (as text and encoded)\n",
        "\n",
        "print(\"--- Training data, predictive features, first row ---\")\n",
        "print(encoderX.inverse_transform(X_train[0:1]))\n",
        "print(\"\\n--- Training data, predicted result, first row ---\")\n",
        "print(encoderY.inverse_transform(y_train[0:1]))\n",
        "print(\"\\n--- Training data, predictive features, first row, one-hot encoded ---\")\n",
        "print(X_train[0:1])\n",
        "print(\"\\n--- Training data, predicted result, first row, one-hot encoded ---\")\n",
        "print(y_train[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jCykZfQJuI-"
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=inputDims, activation='relu'))\n",
        "model.add(Dense(6, input_dim=inputDims, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvzIMsplJDWs"
      },
      "source": [
        "# make class predictions with the model\n",
        "\n",
        "print(\"===== Results from final layer of the first 5 items in test set =====\")\n",
        "t = model.predict(X_test)\n",
        "print(\"1: \" + str(t[0]))\n",
        "print(\"2: \" + str(t[1]))\n",
        "print(\"3: \" + str(t[2]))\n",
        "print(\"4: \" + str(t[3]))\n",
        "print(\"5: \" + str(t[4]))\n",
        "\n",
        "# calculate accuracy\n",
        "totalCorrect = 0\n",
        "predictions = []\n",
        "for i in range(0,len(list(y_test))): \n",
        "  tempPred = np.argmax(model.predict(X_test[i], verbose=0), axis=None)\n",
        "  if (tempPred < numberValidPOS ): predictions.append(tempPred)\n",
        "  else: predictions.append(0)  # It is possible for the NN to give predictions that are outside of the realm of the labelEncoder. This catches them.\n",
        "for i in range(0,len(list(y_test))): \n",
        "  if (predictions[i] == y_test[i]):\n",
        "    totalCorrect += 1\n",
        "accuracy = round((totalCorrect / len(list(y_test)))*100,0)\n",
        "\n",
        "print(\"\\n===== Size of test set =====\")\n",
        "print(len(list(y_test)))\n",
        "print(\"\\n===== Test data, predictive features, first 15 rows =====\")\n",
        "print(encoderX.inverse_transform(X_test[0:15]))\n",
        "print(\"\\n===== Test data, predicted result, first 15 rows =====\")\n",
        "print(predictions[0:15])\n",
        "print(\"\\n===== Test data, expected result, first 15 rows =====\")\n",
        "print(encoderY.inverse_transform(y_test[0:15]))\n",
        "print(\"\\n===== Accuracy of test set =====\")\n",
        "print(str(accuracy) + \"%\")\n",
        "print(\"\\n===== Predictions =====\")\n",
        "\n",
        "\n",
        "isItCorrect = \"\"\n",
        "\n",
        "for i in range(15):\n",
        "  \n",
        "  if (i < 9): itemNum = \"0\" + str(i+1) \n",
        "  else: itemNum = str(i+1)\n",
        "  \n",
        "  if (predictions[i] == y_test[i]): isItCorrect = \"*Correct!*\"\n",
        "  else: isItCorrect = \"\"\n",
        "  \n",
        "  print(\"item \" + itemNum + \": Predicted: \" + str(predictions[i]) + \" /   \" + str(encoderY.inverse_transform([predictions[i]])) + \"  \\tActual value: \" + str(y_test[i]) + \" / \" + str(encoderY.inverse_transform([y_test[i]])) + \" \\t\" + str(isItCorrect)  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXvmMu0uRiBD"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nijl0CEq3H8z"
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}