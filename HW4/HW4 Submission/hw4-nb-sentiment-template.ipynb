{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BO6CaG5I95qX"
   },
   "source": [
    "# Exercise 4.3: Naïve Bayes Classification\n",
    "Kevin King (Kevin.M.King.24@dartmouth.edu)<br>\n",
    "Dartmouth College, LING48, Spring 2023\n",
    "\n",
    "My Implementation (`runNBTest` function below):\n",
    "* Read positive and negative reviews from specified files.\n",
    "* Extract bag-of-words features from the reviews.\n",
    "* Split the data into training and testing sets based on a given cutoff.\n",
    "* Train a Naive Bayes classifier on the training set.\n",
    "* Evaluate the classifier's performance on the testing set:\n",
    "    * Calculate accuracy, precision, recall, and F-measure for positive and negative classes.\n",
    "    * Print the evaluation metrics.\n",
    "* Show the most informative features of the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Do4rReRL-CC3"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import itertools\n",
    "import collections\n",
    "from nltk import word_tokenize\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics.scores import precision, recall, f_measure\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bo1FBNHw-tF-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the 'punkt' library for NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "59NSDuDO-INm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fDzyiMACkdQl9gRwRQrL0jxI35o9K8-H\n",
      "To: /Users/kevin/Desktop/Dartmouth/2022-23/23S/CS72/HW4/templates-hw4/hw5-nb-files.zip\n",
      "100%|████████████████████████████████████████| 424k/424k [00:00<00:00, 8.88MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  hw5-nb-files.zip\n",
      "replace google-pos.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Download files\n",
    "url = \"https://drive.google.com/uc?id=1fDzyiMACkdQl9gRwRQrL0jxI35o9K8-H\"\n",
    "output = 'hw5-nb-files.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "!unzip -j $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: `bigram_word_feats` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GHJs3kQ6-E0G"
   },
   "outputs": [],
   "source": [
    "# Function to construct a bag of words with both unigrams and bigrams\n",
    "# https://streamhacker.com/2010/05/24/\n",
    "# text-classification-sentiment-analysis-stopwords-collocations/\n",
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "  \n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "\n",
    "    tupledWords = []\n",
    "    for w in words:\n",
    "        tempList = []\n",
    "        tempList.append(w)\n",
    "        tempTuple = tuple(tempList)\n",
    "        tupledWords.append(tempTuple)\n",
    "\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(tupledWords, bigrams)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: `runNBTest` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNBTest(filenamePos, filenameNeg, cutoff, numFeats):\n",
    "    # We will store the negative and positive reviews here\t\n",
    "    posReviewsText = []\n",
    "    negReviewsText = []\n",
    "\n",
    "    # Open the file containing the positive reviews\n",
    "    filePos = open(filenamePos, \"r\")\n",
    "    posReviewsText = filePos.readlines()\n",
    "\n",
    "    # Open the file containing the negative reviews\n",
    "    fileNeg = open(filenameNeg, \"r\")\n",
    "    negReviewsText = fileNeg.readlines()\n",
    "\n",
    "    # This will contain the bag-of-words for positive and negative reviews\n",
    "    negfeats = []\n",
    "    posfeats = []\n",
    "\n",
    "    # For every positive review:\n",
    "    # (1) tokenize it, (2) extract the bag-of-words as features, and (3) append it to the positive features.\n",
    "    for f in posReviewsText:\n",
    "        tokens = word_tokenize(f)\n",
    "        wordFeats = bigram_word_feats(tokens)\n",
    "        posfeats.append((wordFeats, 'pos'))\n",
    "\n",
    "    # For every negative review:\n",
    "    # (1) tokenize it, (2) extract the bag-of-words as features, and (3) append it to the negative features.\n",
    "    for f in negReviewsText:\n",
    "        tokens = word_tokenize(f)\n",
    "        wordFeats = bigram_word_feats(tokens)\n",
    "        negfeats.append((wordFeats, 'neg'))\n",
    "\n",
    "    # Get the number of elements that will be in the training set\n",
    "    negcutoff = int(len(negfeats) * cutoff)\n",
    "    poscutoff = int(len(posfeats) * cutoff)\n",
    "\n",
    "    # Make the training and testing sets\n",
    "    trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "    testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "    print('train on ' + str(len(trainfeats)) + ' instances, test on ' + str(len(testfeats)) + ' instances')\n",
    "\n",
    "    # Make a classifier based on the training features\n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "    # Create two blank dictionaries that will contain the goldLabels and the predictedLabels\n",
    "    goldLabels = collections.defaultdict(set)\n",
    "    predictedLabels = collections.defaultdict(set)\n",
    "    \n",
    "    # Get the gold labels and the model predictions for every item in the test set\n",
    "    # and put the labels and the predictions in a Python dictionary\n",
    "    for i, (feats, label) in enumerate(testfeats):\n",
    "        # Add the gold labels to the goldLabels dictionary\n",
    "        goldLabels[label].add(i)\n",
    "        # Get the model's predictions (the \"observed\" labels)\n",
    "        observed = classifier.classify(feats)\n",
    "        # Add the model predictions to the predictedLabels dictionary\n",
    "        predictedLabels[observed].add(i)\n",
    "\n",
    "    # Calculate the precision, recall, and F-measure for the positive and negative sets\n",
    "    posPrecision = precision(goldLabels['pos'], predictedLabels['pos'])\n",
    "    posRecall = recall(goldLabels['pos'], predictedLabels['pos'])\n",
    "    negPrecision = precision(goldLabels['neg'], predictedLabels['neg'])\n",
    "    negRecall = recall(goldLabels['neg'], predictedLabels['neg'])\n",
    "    negF = f_measure(goldLabels['neg'], predictedLabels['neg'])\n",
    "    posF = f_measure(goldLabels['pos'], predictedLabels['pos'])\n",
    "\n",
    "    # Print the accuracy, precisions, recalls, and F-values\n",
    "    print('accuracy:      ' + str(nltk.classify.util.accuracy(classifier, testfeats)))\n",
    "    print('pos precision: ' + str(posPrecision))\n",
    "    print('pos recall:    ' + str(posRecall))\n",
    "    print('neg precision: ' + str(negPrecision))\n",
    "    print('neg recall:    ' + str(negRecall))\n",
    "    print('neg F-measure: ' + str(negF))\n",
    "    print('pos F-measure: ' + str(posF))\n",
    "\n",
    "    # Print the most informative features\n",
    "    classifier.show_most_informative_features(n=numFeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AMAZON ===\n",
      "train on 800 instances, test on 200 instances\n",
      "accuracy:      0.89\n",
      "pos precision: 0.90625\n",
      "pos recall:    0.87\n",
      "neg precision: 0.875\n",
      "neg recall:    0.91\n",
      "neg F-measure: 0.892156862745098\n",
      "pos F-measure: 0.8877551020408163\n",
      "Most Informative Features\n",
      "              ('Great',) = True              pos : neg    =     40.3 : 1.0\n",
      "               ('nice',) = True              pos : neg    =     13.0 : 1.0\n",
      "              ('smart',) = True              pos : neg    =     12.3 : 1.0\n",
      "         ('people', ',') = True              pos : neg    =     11.7 : 1.0\n",
      "              ('learn',) = True              pos : neg    =     11.0 : 1.0\n",
      "      ('opportunities',) = True              pos : neg    =      9.8 : 1.0\n",
      "           ('benefits',) = True              pos : neg    =      9.7 : 1.0\n",
      "         ('to', 'learn') = True              pos : neg    =      9.0 : 1.0\n",
      "            ('balance',) = True              neg : pos    =      8.8 : 1.0\n",
      "                ('Not',) = True              neg : pos    =      7.8 : 1.0\n",
      "  ('opportunity', 'for') = True              pos : neg    =      7.7 : 1.0\n",
      "               ('does',) = True              neg : pos    =      7.7 : 1.0\n",
      "               ('rate',) = True              neg : pos    =      7.7 : 1.0\n",
      "                 ('No',) = True              neg : pos    =      7.4 : 1.0\n",
      "               ('Good',) = True              pos : neg    =      7.0 : 1.0\n",
      "          ('You', 'get') = True              pos : neg    =      7.0 : 1.0\n",
      "        ('work', 'with') = True              pos : neg    =      7.0 : 1.0\n",
      "       ('long', 'hours') = True              neg : pos    =      7.0 : 1.0\n",
      "           ('get', 'to') = True              pos : neg    =      7.0 : 1.0\n",
      "          ('a', 'great') = True              pos : neg    =      7.0 : 1.0\n",
      "                ('fun',) = True              pos : neg    =      7.0 : 1.0\n",
      "     ('life', 'balance') = True              neg : pos    =      6.6 : 1.0\n",
      "          ('.', 'Great') = True              pos : neg    =      6.3 : 1.0\n",
      "              ('times',) = True              neg : pos    =      6.3 : 1.0\n",
      "             ('decent',) = True              pos : neg    =      6.3 : 1.0\n",
      "\n",
      "\n",
      "=== GOOGLE ===\n",
      "train on 800 instances, test on 200 instances\n",
      "accuracy:      0.885\n",
      "pos precision: 0.9230769230769231\n",
      "pos recall:    0.84\n",
      "neg precision: 0.8532110091743119\n",
      "neg recall:    0.93\n",
      "neg F-measure: 0.8899521531100479\n",
      "pos F-measure: 0.8795811518324608\n",
      "Most Informative Features\n",
      "              ('Great',) = True              pos : neg    =     29.8 : 1.0\n",
      "              ('perks',) = True              pos : neg    =     25.4 : 1.0\n",
      "               ('free',) = True              pos : neg    =     21.0 : 1.0\n",
      "            ('amazing',) = True              pos : neg    =     17.7 : 1.0\n",
      "          ('hard', 'to') = True              neg : pos    =     15.7 : 1.0\n",
      "               ('Good',) = True              pos : neg    =     15.0 : 1.0\n",
      "           ('can', 'be') = True              neg : pos    =     14.2 : 1.0\n",
      "          ('sometimes',) = True              neg : pos    =     13.7 : 1.0\n",
      "        ('interesting',) = True              pos : neg    =     13.0 : 1.0\n",
      "           ('food', ',') = True              pos : neg    =     12.6 : 1.0\n",
      "          ('difficult',) = True              neg : pos    =     12.3 : 1.0\n",
      "              ('times',) = True              neg : pos    =     12.3 : 1.0\n",
      "                ('fun',) = True              pos : neg    =     10.2 : 1.0\n",
      "           ('politics',) = True              neg : pos    =      9.7 : 1.0\n",
      "           ('benefits',) = True              pos : neg    =      9.5 : 1.0\n",
      "        ('culture', ',') = True              pos : neg    =      9.0 : 1.0\n",
      "            ('awesome',) = True              pos : neg    =      9.0 : 1.0\n",
      "     ('and', 'benefits') = True              pos : neg    =      8.3 : 1.0\n",
      "            ('nothing',) = True              neg : pos    =      8.3 : 1.0\n",
      "    ('environment', ',') = True              pos : neg    =      8.3 : 1.0\n",
      "               ('food',) = True              pos : neg    =      8.2 : 1.0\n",
      "               ('Free',) = True              pos : neg    =      7.8 : 1.0\n",
      "                ('not',) = True              neg : pos    =      7.8 : 1.0\n",
      "       ('organization',) = True              neg : pos    =      7.7 : 1.0\n",
      "             (\"'s\", 'a') = True              neg : pos    =      7.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AMAZON ===\")\n",
    "runNBTest(\"amazon-pos.txt\", \"amazon-neg.txt\", 0.8, 25)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== GOOGLE ===\")\n",
    "runNBTest(\"google-pos.txt\", \"google-neg.txt\", 0.8, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw5-nb-sentiment-template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
