{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXcge0wSzBb6"
   },
   "source": [
    "# Exercise 4.1B: Perplexity\n",
    "Kevin King (Kevin.M.King.24@dartmouth.edu)<br>\n",
    "Dartmouth College, LING48, Spring 2023\n",
    "\n",
    "Please study the links below and attempt to modify the program according to the homework instructions.\n",
    "\n",
    "Documentation of the NLTK.LM package:<br>\n",
    "https://www.nltk.org/api/nltk.lm.html\n",
    "\n",
    "How to extract n-gram probabilities:<br>\n",
    "https://stackoverflow.com/questions/54962539/how-to-get-the-probability-of-bigrams-in-a-text-of-sentences\n",
    "\n",
    "Calculating perplexity with NLTK:<br>\n",
    "https://stackoverflow.com/questions/54941966/how-can-i-calculate-perplexity-using-nltk\n",
    "\n",
    "Sentences I chose: \n",
    "* Five-word sequence that DOES appear in the corpus: \"this is a dreadful sentence\"\n",
    "* Five-word sequence that appears in your bigram/trigram model from part 1A: \"put but a losing office\"\n",
    "* Four-word sequence with at least one word that does not appear in your n-gram model: \"love loving not dogs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MXbg5lhzpAaA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (3.4)\n",
      "Requirement already satisfied: singledispatch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nltk==3.4) (4.0.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nltk==3.4) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upgrade from version in the VM\n",
    "!pip install -U nltk==3.4\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N1vCMVOyo8AA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io \n",
    "import random\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
    "from nltk.lm import MLE, NgramCounter, Vocabulary\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, sent_tokenize, bigrams, trigrams\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SLyEbEgUq-RW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pW_rn9oZi3Ax23-ezP8K3AcR5QhtLR-a\n",
      "To: /Users/kevin/Desktop/Dartmouth/2022-23/23S/CS72/HW4/templates-hw4/ling28-corpora.tar.gz\n",
      "100%|██████████████████████████████████████| 22.8M/22.8M [00:01<00:00, 13.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and decompress corpora\n",
    "url = \"https://drive.google.com/uc?id=1pW_rn9oZi3Ax23-ezP8K3AcR5QhtLR-a\"\n",
    "output = 'ling28-corpora.tar.gz'\n",
    "gdown.download(url, output, quiet=False)\n",
    "!tar -xf ling28-corpora.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dWECRfnWp02P"
   },
   "outputs": [],
   "source": [
    "# Open file\n",
    "file = io.open('english - shakespeare.txt', encoding='utf8')\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA-utVqO2goN"
   },
   "source": [
    "# Preprocess the tokenized text for language modelling\n",
    "https://stackoverflow.com/questions/54959340/nltk-language-modeling-confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qqfeSN9X2eOl"
   },
   "outputs": [],
   "source": [
    "# Preprocess the tokenized text for language modelling\n",
    "n = 2\n",
    "paddedLine = [list(pad_both_ends(word_tokenize(text.lower()), n))]\n",
    "train, vocab = padded_everygram_pipeline(n, paddedLine)\n",
    "\n",
    "# Train a n-gram maximum likelihood estimation model.\n",
    "model = MLE(n) \n",
    "model.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUZIWG1q5aa0"
   },
   "source": [
    "How to extract n-gram probabilities:<br>\n",
    "https://stackoverflow.com/questions/54962539/how-to-get-the-probability-of-bigrams-in-a-text-of-sentences\n",
    "\n",
    "Calculating perplexity with NLTK:<br>\n",
    "https://stackoverflow.com/questions/54941966/how-can-i-calculate-perplexity-using-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JJNrb2fI5W5U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE Estimates: [(('is', ('this',)), 0.07187454624655147), (('a', ('is',)), 0.0656846396146007), (('dreadful', ('a',)), 0.0003203895937459951), (('sentence', ('dreadful',)), 0.01639344262295082)]\n",
      "MLE Estimates: [(('but', ('put',)), 0.005802707930367505), (('a', ('but',)), 0.03361085414739439), (('losing', ('a',)), 0.00012815583749839805), (('office', ('losing',)), 0.05)]\n",
      "MLE Estimates: [(('loving', ('love',)), 0.00046490004649000463), (('not', ('loving',)), 0.008695652173913044), (('dogs', ('not',)), 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# NLTK will calculate the perplexity of these sentences\n",
    "test_sentences = ['this is a dreadful sentence', 'put but a losing office', 'love loving not dogs']\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in test_sentences]\n",
    "\n",
    "# Probability of bigrams\n",
    "test_data = [bigrams(t,  pad_right=False, pad_left=False) for t in tokenized_text]\n",
    "for test in test_data:\n",
    "    print (\"MLE Estimates:\", [((ngram[-1], ngram[:-1]),model.score(ngram[-1], ngram[:-1])) for ngram in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iZEXKD_j5vkL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP(this is a dreadful sentence):79.68987102980361\n",
      "PP(put but a losing office):168.18812749362763\n",
      "PP(love loving not dogs):inf\n"
     ]
    }
   ],
   "source": [
    "# Perplexity of bigrams\n",
    "test_data = [bigrams(t,  pad_right=False, pad_left=False) for t in tokenized_text]\n",
    "for i, test in enumerate(test_data):\n",
    "    print(\"PP({0}):{1}\".format(test_sentences[i], model.perplexity(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4-ngram-template2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
